//Problem 1:

1) T(N) = 2T(N-1) + 1
It doesn't fit the master theorem ==> using recursion tree method. 
At level 0 (the root), the cost is 1 (from the +1 part of the recurrence).
At level 1, there are 2 recursive calls, each contributing an additional +1, so the total cost at this level is 2^1
This pattern continues, with each level i contributing 2^i to the total 
The depth of the tree is N, as each level decreases the problem size by 1, and the total cost is the sum of the costs at each level.
The sum of costs from level 0 to Nâˆ’1 is:
==> T(N) = 1 + 2 + 2^2 + ... + 2^(N-1) = 2^N -1

2) T(N) = 3T(N-1) + n

3) T(N) = 9T(N/2) + n2

4) T(N) = 100T(N/2) + nlog2cn + 1  (c is a constant)

5) T(N) = 4T(N/2) + n2logn

6) T(N) = 5T(N/2) + n2/logn

//Problem 2:
The loop running 10n times corresponds to a linear operation for each function call, contributing O(10n) or simply O(n) complexity for each invocation of the function.
After the loop, the function makes two recursive calls with n/2 as the argument for each.
Thus, the recurrence relation that represents the time complexity of yetAnotherFunc(n) can be expressed as:
T(n) = 2T(n/2) + O(n)
where a = 2, b = 2, f(n) = O(n) 
a,b >= 1 the f(n) = theta(n^(logb(a)-e)*log^k(n)) = theta(n^(1-e) * log^k(n)), but f(n) = O(n) ===> e = 0; k = 0
then T(n) = theta(n^(logb(a)-e)*log^(k+1)(n)) = theta(n*logn)
Thus the given recurrence relation: T(n) = theta(n*logn)
